# train

filepath_X = 'X.txt'
df = read_csv(filepath_or_buffer =filepath_X, header=0, sep=',')
df['op1_sum'] = sum(df[df.columns[2:19]],axis = 1)
for col in df.columns[2:19]:
    df[col+'_pc'] = df[col]/df['op1_sum']
    df.drop(col,axis = 1, inplace = True)
df['op2_sum'] = sum(df[df.columns[2:155]],axis = 1)
for col in df.columns[2:155]:
    df[col+'_pc'] = df[col]/df['op2_sum']
    df.drop(col,axis = 1, inplace = True)
    
filepath1 = 'creating features/countlines_train.csv'
df1= read_csv(filepath_or_buffer =filepath1, header=0, sep=',')
df1['line_sum'] = sum(df1[[1,2,3,4]],axis = 1)
for col in df1.columns[1:5]:
    df1[col+'_pc'] = df1[col]/df1['line_sum']
    df1.drop(col,axis = 1, inplace = True)
df = pd.merge(df,df1,left_on='Id',right_on = 'ID')
df.drop('ID',axis = 1, inplace = True)

path, dirs, files = os.walk("creating features/size_??_00_FF_train").next()
pieces = []
if '.DS_store' in files:
    files.remove('.DS_Store')
for i,filename in enumerate(files):
    pieces.append(read_csv(filepath_or_buffer =path+'/'+filename, header=0, sep=','))
    pieces[i].rename(columns={'0':'00','1':'01','2':'02','3':'03','4':'04','5':'05','6':'06','7':'07','8':'08','9':'09'},inplace=True)
df_temp = pd.concat(pieces)
df_temp['2b_sum'] = sum(df_temp[df_temp.columns[3:]],axis = 1)
for col in df_temp.columns[3:(-1)]:
    df_temp[col+'_pc'] = df_temp[col]/df_temp['2b_sum']
    df_temp.drop(col,axis = 1, inplace = True)

df = pd.merge(df,df_temp,left_on='Id',right_on = 'ID')
df.drop('ID',axis = 1, inplace = True)

" convert NaN to 0 "
for col in df.columns[2:]:
    df[col][isnan(df[col])]=0
    df[col][isinf(df[col])]=0


# test
filepath_X = 'X_test.csv'
df_test = read_csv(filepath_or_buffer =filepath_X, header=0, sep=',')
df_test.drop('Unnamed: 0',axis = 1,inplace = True)
df_test['op1_sum'] = sum(df_test[df_test.columns[1:18]],axis = 1)
for col in df_test.columns[1:18]:
    df_test[col+'_pc'] = df_test[col]/df_test['op1_sum']
    df_test.drop(col,axis = 1, inplace = True)
df_test['op2_sum'] = sum(df_test[df_test.columns[1:154]],axis = 1)
for col in df_test.columns[1:154]:
    df_test[col+'_pc'] = df_test[col]/df_test['op2_sum']
    df_test.drop(col,axis = 1, inplace = True)
df_test['Id'] = [string.split('.')[0] for string in df_test['Id']]
                 
filepath1 = 'creating features/countlines_test.csv'
df_test1= read_csv(filepath_or_buffer =filepath1, header=0, sep=',')
df_test1['line_sum'] = sum(df_test1[[1,2,3,4]],axis = 1)
for col in df_test1.columns[1:5]:
    df_test1[col+'_pc'] = df_test1[col]/df_test1['line_sum']
    df_test1.drop(col,axis = 1, inplace = True)
df_test = pd.merge(df_test,df_test1,left_on='Id',right_on = 'ID')
df_test.drop('ID',axis = 1, inplace = True)

path, dirs, files = os.walk("creating features/size_??_00_FF_test").next()
pieces = []
files.remove('.DS_Store')
for i,filename in enumerate(files):
    pieces.append(read_csv(filepath_or_buffer =path+'/'+filename, header=0, sep=','))
    pieces[i].rename(columns={'0':'00','1':'01','2':'02','3':'03','4':'04','5':'05','6':'06','7':'07','8':'08','9':'09'},inplace=True)
df_test_temp = pd.concat(pieces)
df_test_temp['2b_sum'] = sum(df_test_temp[df_test_temp.columns[3:]],axis = 1)

for col in df_test_temp.columns[3:(-1)]:
    df_test_temp[col+'_pc'] = df_test_temp[col]/df_test_temp['2b_sum']
    df_test_temp.drop(col,axis = 1, inplace = True)

df_test = pd.merge(df_test,df_test_temp,left_on='Id',right_on = 'ID')
df_test.drop('ID',axis = 1, inplace = True)

" convert NaN to 0 "
for col in df_test.columns[2:]:
    df_test[col][isnan(df_test[col])]=0
    df_test[col][isinf(df_test[col])]=0